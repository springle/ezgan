import tensorflow as tf
import datetime

from tensorflow.examples.tutorials.mnist import input_data

mnist = input_data.read_data_sets("MNIST_data/")


def discriminator(x_image, reuse_variables=None):
    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:
        # First convolutional and pool layers
        # These search for 32 different 5 x 5 pixel features
        d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))
        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))
        d1 = tf.nn.conv2d(input=x_image, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')
        d1 = d1 + d_b1
        d1 = tf.nn.relu(d1)
        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

        # Second convolutional and pool layers
        # These search for 64 different 5 x 5 pixel features
        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))
        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))
        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')
        d2 = d2 + d_b2
        d2 = tf.nn.relu(d2)
        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

        # First fully connected layer
        d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))
        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))
        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])
        d3 = tf.matmul(d3, d_w3)
        d3 = d3 + d_b3
        d3 = tf.nn.relu(d3)

        # Second fully connected layer
        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))
        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))

        # Final layer
        d4 = tf.matmul(d3, d_w4) + d_b4
        # d4 = tf.sigmoid(d4)

        # d4 dimensions: batch_size x 1

        return d4


def generator(batch_size, z_dim):
    z = tf.random_normal([batch_size, z_dim], mean=0, stddev=1, name='z')
    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32,
                           initializer=tf.truncated_normal_initializer(stddev=0.02))
    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))
    g1 = tf.matmul(z, g_w1) + g_b1
    g1 = tf.reshape(g1, [-1, 56, 56, 1])
    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')
    g1 = tf.nn.relu(g1)

    # Generate 50 features
    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim / 2], dtype=tf.float32,
                           initializer=tf.truncated_normal_initializer(stddev=0.02))
    g_b2 = tf.get_variable('g_b2', [z_dim / 2], initializer=tf.truncated_normal_initializer(stddev=0.02))
    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')
    g2 = g2 + g_b2
    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')
    g2 = tf.nn.relu(g2)
    g2 = tf.image.resize_images(g2, [56, 56])

    # Generate 25 features
    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim / 2, z_dim / 4], dtype=tf.float32,
                           initializer=tf.truncated_normal_initializer(stddev=0.02))
    g_b3 = tf.get_variable('g_b3', [z_dim / 4], initializer=tf.truncated_normal_initializer(stddev=0.02))
    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')
    g3 = g3 + g_b3
    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')
    g3 = tf.nn.relu(g3)
    g3 = tf.image.resize_images(g3, [56, 56])

    # Final convolution with one output channel
    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim / 4, 1], dtype=tf.float32,
                           initializer=tf.truncated_normal_initializer(stddev=0.02))
    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))
    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')
    g4 = g4 + g_b4
    g4 = tf.sigmoid(g4)

    # No batch normalization at the final layer, but we do add
    # a sigmoid activator to make the generated images crisper.
    # Dimensions of g4: batch_size x 28 x 28 x 1

    return g4


def main(server, log_dir, context):

    batch_size = context.get("batch_size") or 50
    z_dimensions = context.get("z_dimensions") or 100
    g_learning_rate = context.get("g_learning_rate") or 0.004
    d_fake_learning_rate = context.get("g_learning_rate") or 0.001
    d_real_learning_rate = context.get("g_learning_rate") or 0.001
    beta1 = context.get("beta1") or 0.8

    x_placeholder = tf.placeholder("float", shape=[None, 28, 28, 1], name='x_placeholder')
    # x_placeholder is for feeding input images to the discriminator

    Gz = generator(batch_size, z_dimensions)
    # Gz holds the generated images

    Dx = discriminator(x_placeholder)
    # Dx will hold discriminator prediction probabilities
    # for the real MNIST images

    Dg = discriminator(Gz, reuse_variables=True)
    # Dg will hold discriminator prediction probabilities for generated images

    # == LOSSES AND OPTIMIZERS ==
    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))

    d_loss_real = tf.reduce_mean(
        tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.fill([batch_size, 1], 0.9)))
    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))

    tf.summary.scalar('Generator_loss', g_loss)
    tf.summary.scalar('Discriminator_loss_real', d_loss_real)
    tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)

    d_real_count_ph = tf.placeholder(tf.float32)
    d_fake_count_ph = tf.placeholder(tf.float32)
    g_count_ph = tf.placeholder(tf.float32)

    tf.summary.scalar('d_real_count', d_real_count_ph)
    tf.summary.scalar('d_fake_count', d_fake_count_ph)
    tf.summary.scalar('g_count', g_count_ph)

    images_for_tensorboard = Gz
    tf.summary.image('Generated_images', images_for_tensorboard, 10)
    merged = tf.summary.merge_all()
    logdir = log_dir + "/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S") + "/"

    tvars = tf.trainable_variables()

    d_vars = [var for var in tvars if 'd_' in var.name]
    g_vars = [var for var in tvars if 'g_' in var.name]

    global_step = tf.Variable(0, name='global_step', trainable=False)

    # Discriminator training operations
    d_trainer_fake = tf.train.AdamOptimizer(d_fake_learning_rate, beta1=beta1).minimize(
        d_loss_fake, var_list=d_vars, global_step=global_step)
    d_trainer_real = tf.train.AdamOptimizer(d_real_learning_rate, beta1=beta1).minimize(
        d_loss_real, var_list=d_vars, global_step=global_step)

    # Generator training operations
    g_trainer = tf.train.AdamOptimizer(g_learning_rate, beta1=beta1).minimize(
        g_loss, var_list=g_vars, global_step=global_step)

    is_chief = server.server_def.task_index == 0
    with tf.train.MonitoredTrainingSession(master=server.target,
                                           is_chief=is_chief) as sess:

        # Create writer
        if is_chief:
            writer = tf.summary.FileWriter(logdir, sess.graph)

        # == TRAINING LOOP ==
        gLoss = 1
        dLossFake, dLossReal = 0, 0
        d_real_count, d_fake_count, g_count = 0, 0, 0
        for i in range(50000):
            real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])
            if dLossFake > 0.7:
                # Train discriminator on generated images
                _, dLossReal, dLossFake, gLoss = sess.run([d_trainer_fake, d_loss_real, d_loss_fake, g_loss],
                                                          {x_placeholder: real_image_batch})
                d_fake_count += 1

            if gLoss > 0.5:
                # Train the generator
                _, dLossReal, dLossFake, gLoss = sess.run([g_trainer, d_loss_real, d_loss_fake, g_loss],
                                                          {x_placeholder: real_image_batch})
                g_count += 1

            if dLossReal > 0.45:
                # If the discriminator classifies real images as fake,
                # train discriminator on real values
                _, dLossReal, dLossFake, gLoss = sess.run([d_trainer_real, d_loss_real, d_loss_fake, g_loss],
                                                          {x_placeholder: real_image_batch})
                d_real_count += 1

            gstep = tf.train.global_step(sess, global_step)

            if is_chief and (i % 50 == 0):
                real_image_batch = mnist.validation.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])
                summary = sess.run(merged, {x_placeholder: real_image_batch, d_real_count_ph: d_real_count,
                                            d_fake_count_ph: d_fake_count, g_count_ph: g_count})
                writer.add_summary(summary, gstep)
                d_real_count, d_fake_count, g_count = 0, 0, 0
